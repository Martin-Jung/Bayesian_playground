---
title: "Rethinking with BRMS"
output: html_notebook
---

# Bayesian models with BRMS

Redoing some of the Rethinking book with the *tidyverse* and *brms* package. [https://bookdown.org/content/1850/index.html](Tutorial and code here.)
Mainly using MCMC via Stan and the *brms* package. Idea is to redo some of the examples by McElreath but with brms or stan directly.

Load all necessary packages
```{r,echo=FALSE,message=FALSE, warning=FALSE, include=FALSE}
source("00_PackagesFunctions.R")
```

# Prior recommendations from the [https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations](stan project).

## Stan

Avoid using uniform priors!
You think a parameter could be anywhere from 0 to 1, so you set the prior to uniform(0,1). Try normal(.5,.5) instead.

## Aim to keep all parameters scale-free. Many ways of doing this:

* Scale by sd of data. This is done in education settings, here the sd is the sd of test scores of all kids in a single grade, for example
*  In a regression, take logs of (positive-constrained) predictors and outcomes, then coefs can be interpreted as elasticities
*  Scale by some conventional value, for example if a parameter has a "typical" value of 4.5, you could work with log(theta/4.5). We did some things like this in our PK/PD project with Sebastian1. For example, in epidemiological studies it is common to standardize with the expected number of events.

Keep paremeters scale free. Divide by SD or better MAD

<hr>
Code start

```{r}
# The first model from McElReath
b3.1 <- brm(data = list(w = 6), 
      family = binomial(link = "identity"),
      w | trials(9) ~ 1,
      prior = prior(beta(1, 1), class = Intercept),
      control = list(adapt_delta = .99))

posterior_summary(b3.1)["b_Intercept", ] %>% round(digits = 2)

# Get simulation draws instead
fitted_samples <- fitted(b3.1, summary = F, scale = "linear") %>%   as_tibble()

```

# Chapter 4 - Linear models

```{r}
library(rethinking)
data(Howell1)
d <- Howell1
detach(package:rethinking,unload = T)

# Linear model with brms
d2 <- d %>% filter(age >= 18)

b4.1 <- brm(data = d2, family = gaussian,
      height ~ 1, # Intercept only model
      prior = c(prior(normal(178, 20), class = Intercept), # mu
                prior(uniform(0, 50), class = sigma)), # sd
      iter = 31000, warmup = 30000, chains = 4, cores = 4)

# Repeat but with a cauchy prior
b4.1_half_cauchy <- brm(data = d2, family = gaussian,
      height ~ 1,
      prior = c(prior(normal(178, 20), class = Intercept),
                prior(cauchy(0, 1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4)

# Inspect the chains
plot(b4.1_half_cauchy)
# Or via shiny interface
launch_shinystan(b4.1_half_cauchy)
b4.1_half_cauchy$fit

# Covariance of brms object
post <- posterior_samples(b4.1_half_cauchy)
cov(post[, 1:2])

# Or other ways of summarising:
posterior_summary(b4.1_half_cauchy)


```
-

```{r}
# Multiple linear regression - 4.4.2
b4.3 <- brm(data = d2, family = gaussian,
      height ~ 1 + weight,
      prior = c(prior(normal(156, 100), class = Intercept), # prior for intercep
                prior(normal(0, 10), class = b), # for beta
                #prior(uniform(0, 50), class = sigma)), # for sigma
                prior(cauchy(0,1), class = sigma)), # cauchy uses less warmup
      iter = 41000, warmup = 40000, chains = 4, cores = 4)

# Center and refit (with cauchy prior)
d2$weight.c <- d2$weight - mean(d2$weight,na.rm = T)

b4.4 <- brm(data = d2, family = gaussian,
      height ~ 1 + weight.c,
      prior = c(prior(normal(178, 100), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(cauchy(0, 1), class = sigma)),
      iter = 46000, warmup = 45000, chains = 4, cores = 4,
      control = list(adapt_delta = 0.8, 
                     max_treedepth = 10))

plot(b4.4) # Check
posterior_summary(b4.4)[1:3, ] # Summarise
#pairs(b4.4)


post <- posterior_samples(b4.3)
# Mean at 50
mu_at_50 <- post %>% transmute(mu_at_50 = b_Intercept + b_weight * 50)
mu_at_50 %>%
  ggplot(aes(x = mu_at_50)) +
  geom_density(size = 0, fill = "royalblue") +
  stat_pointintervalh(aes(y = 0), 
                      point_interval = mode_hdi, .width = .95) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(x = expression(mu["height | weight = 50"])) +
  theme_classic()


# Plot quick regression line and fit uncertainty of mu using brms
weight_seq <- tibble(weight = seq(from = 25, to = 70, by = 1)) # Predata
mu_summary <-fitted(b4.3, 
         newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq)

d2 %>%
  ggplot(aes(x = weight, y = height)) +
  geom_ribbon(data = mu_summary, 
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              fill = "grey70") +
  geom_line(data = mu_summary, 
            aes(y = Estimate)) +
  geom_point(color = "navyblue", shape = 1, size = 1.5, alpha = 2/3) +
  coord_cartesian(xlim = range(d2$weight)) +
  theme(text = element_text(family = "Arial"),
        panel.grid = element_blank())

# ...these simulations (predictions) are the joint consequence of both μ and σ, unlike the results of fitted(), which only reflect μ. 
pred_height <-  predict(b4.3,newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq)
  
d2 %>%
  ggplot(aes(x = weight)) +
  geom_ribbon(data = pred_height, 
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              fill = "grey83") +
  geom_ribbon(data = mu_summary, 
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              fill = "grey70") +
  geom_line(data = mu_summary, aes(y = Estimate)) +
  geom_point(aes(y = height),
             color = "navyblue", shape = 1, size = 1.5, alpha = 2/3) +
  coord_cartesian(xlim = range(d2$weight),
                  ylim = range(d2$height)) +
  theme(text = element_text(family = "Arial"),
        panel.grid = element_blank())

```

# For chapter 5 - Multivariate linear models

```{r}
rm(list = ls());gc() # Cleanup
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
rm(WaffleDivorce)
detach(package:rethinking, unload = T)

# -------------------- #
# Standardize
d <-d %>%
  mutate(MedianAgeMarriage_s = (MedianAgeMarriage - mean(MedianAgeMarriage)) /
           sd(MedianAgeMarriage))

b5.1 <- 
  brm(data = d, family = gaussian,
      Divorce ~ 1 + MedianAgeMarriage_s,
      prior = c(prior(normal(10, 10), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(uniform(0, 10), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4)
b5.1
# Plot
nd <- tibble(MedianAgeMarriage_s = seq(from = -3, to = 3.5, length.out = 30))

# Now use `fitted()` to get the model-implied trajectories
fitd_b5.1 <- 
  fitted(b5.1, newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd)

# Plot
ggplot(data = fitd_b5.1, 
       aes(x = MedianAgeMarriage_s, y = Estimate)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              fill = "firebrick", alpha = 1/5) +
  geom_line(color = "firebrick4") +
  geom_point(data = d, 
             aes(x = MedianAgeMarriage_s, y = Divorce), 
             size = 2, color = "firebrick4") +
  labs(y = "Divorce") +
  coord_cartesian(xlim = range(d$MedianAgeMarriage_s), 
                  ylim = range(d$Divorce)) +
  theme_bw() +
  theme(panel.grid = element_blank())                   

```

Multivariate model

```{r}
d <- d %>% mutate(Marriage_s = (Marriage - mean(Marriage)) / sd(Marriage))

b5.3 <- 
  brm(data = d, family = gaussian,
      Divorce ~ 1 + Marriage_s + MedianAgeMarriage_s,
      prior = c(prior(normal(10, 10), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(uniform(0, 10), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4)

stanplot(b5.3)
# Can also plot using bayes plot (draw from posterior first)
# or using the tidybayes package

library(tidybayes)
post <- posterior_samples(b5.3)

post %>% 
  select(-lp__) %>% 
  gather() %>% 
  
  ggplot(aes(x = value, y = reorder(key, value))) +  # note how we used `reorder()` to arrange the coefficients
  geom_vline(xintercept = 0, color = "firebrick4", alpha = 1/10) +
  geom_halfeyeh(point_interval = mode_hdi, .width = .95, 
                      size = 3/4, color = "firebrick4",fill="grey80") +
  labs(title = "My tidybayes-based coefficient plot",
       x = NULL, y = NULL) +
  theme_bw() +
  theme(panel.grid   = element_blank(),
        panel.grid.major.y = element_line(color = alpha("firebrick4", 1/4), linetype = 3),
        axis.text.y  = element_text(hjust = 0),
        axis.ticks.y = element_blank())

# Generally
tibble(`brms function` = c("fitted", "predict", "residual"),
       mean  = c("same as the data", "same as the data", "in a deviance-score metric"),
       scale = c("excludes sigma", "includes sigma", "excludes sigma"))



```


# Skipping some. Moving on with categorical variables

```{r}
rm(list = ls())
library(rethinking)
data(Howell1)
d <- Howell1
rm(Howell1)
detach(package:rethinking, unload = T)

b5.15 <- brm(data = d, family = gaussian,
      height ~ 1 + male,
      prior = c(prior(normal(178, 100), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(cauchy(0, 2), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4)
print(b5.15)

fitted(b5.15,    newdata = data.frame(male = c(0,1)))
```

<hr>

# Chapter 6
```{r Overfitting}

sppnames <- c( "afarensis","africanus","habilis","boisei", "rudolfensis","ergaster","sapiens")
brainvolcc <- c( 438 , 452 , 612, 521, 752, 871, 1350 )
masskg <- c( 37.0 , 35.5 , 34.5 , 41.5 , 55.5 , 61.0 , 53.5 )
d <- data.frame( species=sppnames , brain=brainvolcc , mass=masskg ) %>% 
  # Standardize Mass
  mutate(mass_s = (mass - mean(mass)) / sd(mass))

# Here we specify our starting values
inits <- list(Intercept = mean(d$brain), # Intercept as mean
              mass_s    = 0, # mass 0
              sigma     = sd(d$brain)) # uncertainty to sd

# Need as many lists as MCMC chains 
# -> Could mix starting values among chains
inits_list <-list(inits, inits, inits, inits)

# The model
b6.8 <- 
  brm(data = d, family = gaussian,
      brain ~ 1 + mass_s,
      prior = c(prior(normal(0, 1000), class = Intercept),
                prior(normal(0, 1000), class = b),
                prior(cauchy(0, 10), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      inits = inits_list)  # Here we put our start values in the `brm()` function
b6.8

# Loglik per HMC iteration
dfLL <- b6.8 %>%
  log_lik() %>%
  as_tibble() %>% 
  # Deviance as sum of likelihood multiplied by -2
  mutate(sums  = rowSums(.),
         deviance = -2*sums)

# Plot deviance
dfLL %>%
  ggplot(aes(x = deviance, y = 0)) +
  geom_halfeyeh(point_interval = median_qi, .width = .95) +
  scale_x_continuous(breaks = quantile(dfLL$deviance, c(.025, .5, .975)),
                     labels = quantile(dfLL$deviance, c(.025, .5, .975)) %>% round(1)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "The deviance distribution") +
  theme_classic() 

```

The WAIC with brms is straight forward for both model comparison and model averaging, however loo seems to be prefered these days

```{r}
library(rethinking)
data(milk)

d <- milk %>%
  filter(complete.cases(.)) %>%
  mutate(neocortex = neocortex.perc / 100)
rm(milk)

detach(package:rethinking, unload = T)
library(brms)

# Initialize with mean and standard deviation
inits <- list(Intercept = mean(d$kcal.per.g),
              sigma     = sd(d$kcal.per.g))

inits_list <-list(inits, inits, inits, inits)

b6.11 <- brm(data = d, family = gaussian,
      kcal.per.g ~ 1, # Intercept only
      prior = c(prior(uniform(-1000, 1000), class = Intercept), # Very uninformative priors
                prior(uniform(0, 100), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      inits = inits_list)

# Second model. Regress agains neocortex
inits <- list(Intercept = mean(d$kcal.per.g),
              neocortex = 0,
              sigma     = sd(d$kcal.per.g))
b6.12 <- brm(data = d, family = gaussian,
      kcal.per.g ~ 1 + neocortex,
      prior = c(prior(uniform(-1000, 1000), class = Intercept),
                prior(uniform(-1000, 1000), class = b),
                prior(uniform(0, 100), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      inits = inits_list)

# Then create some secondary models by updating them
inits <- list(Intercept   = mean(d$kcal.per.g),
              `log(mass)` = 0,
              sigma       = sd(d$kcal.per.g))

b6.13 <-update(b6.12, 
         newdata = d,
         formula = kcal.per.g ~ 1 + log(mass),
         inits   = inits_list)

# Lastly
inits <- list(Intercept   = mean(d$kcal.per.g),
              neocortex   = 0,
              `log(mass)` = 0,
              sigma       = sd(d$kcal.per.g))
b6.14 <- update(b6.13, 
         newdata = d,
         formula = kcal.per.g ~ 1 + neocortex + log(mass),
         inits   = inits_list)

# Compare all
waic(b6.11, b6.12, b6.13, b6.14)
# Model weights
model_weights(b6.11, b6.12, b6.13, b6.14, weights = "waic")

LOO(b6.14)# The LOO

# Averaged parameters across best models
posterior_average(b6.13,b6.14, weights = "waic")

# Now construct a model average model
# we need new data for both the `fitted()` and `pp_average()` functions
nd <- tibble(neocortex = seq(from = .5, to = .8, length.out = 30),
         mass = rep(4.5, times = 30))

# we'll get the `b6.14`-implied trajectory with `fitted()`
fitd_b6.14 <- fitted(b6.14, newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd)

# the model-average trajectory comes from `pp_average()`
pp_average(b6.11, b6.12, b6.13, b6.14,
           weights = "waic",
           method  = "fitted",  # for new data predictions, use `method = "predict"`
           newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd) %>%
  
  # plot Figure 
ggplot(aes(x = neocortex, y = Estimate)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 1/4) +
  geom_line(color   = "red") +
  geom_ribbon(data  = fitd_b6.14, aes(ymin = Q2.5, ymax = Q97.5),
              color = "grey80", fill = "transparent", linetype = 2) +
  geom_line(data = fitd_b6.14, linetype = 2) +
  geom_point(data = d, aes(x = neocortex, y = kcal.per.g), 
             size = 2) +
  labs(y = "kcal.per.g") +
  coord_cartesian(xlim = range(d$neocortex), 
                  ylim = range(d$kcal.per.g)) +
  theme_gray() 


# ----- #
# Bayesian R2
bayes_R2(b6.14)

# Plot marginal effects
plot(marginal_effects(b6.14,
                      spaghetti = T, nsamples = 200),
     points = T,
     point_args = c(alpha = 1/2, size = 1))

```

#
- Chapter 8 is pretty much self explanatory

- Same with 9. Reading through examples there...
But lets fit a distributional mode

```{r}
set.seed(100)
(
  d <-
  tibble(x = rep(0:1, each = 100)) %>% 
  mutate(y = rnorm(n = n(), mean = 100, sd = 10 + x * 10))
  )


d %>% 
  mutate(x = x %>% as.character()) %>% 
  ggplot(aes(x = y, y = x, fill = x)) +
  geom_halfeyeh(point_interval = mean_qi, .width = .68) 
# Both are identical in the mean but differ in the variation

# In berms
b9.1 <- 
  brm(data = d, 
      family = gaussian,
      bf(y ~ 1, sigma ~ 1 + x), # Two formulas! One for mean, one for sigma
      prior = c(prior(normal(100, 10), class = Intercept),
                prior(normal(0, 10),   class = Intercept, dpar = sigma), # dpar for sigma
                prior(normal(0, 10),   class = b,         dpar = sigma)))
print(b9.1)

```

# Chapter 10


```{r Bionomial models}

library(rethinking)
data(chimpanzees)
d <- chimpanzees
library(brms);library(tidyverse)
rm(chimpanzees)

# Intercept only logistic model
b10.1 <-brm(data = d, family = binomial,
      pulled_left ~ 1,
      prior(normal(0, 10), class = Intercept))

# Get intercept only estimates and backtransform
fixef(b10.1) %>% inv_logit_scaled() %>% round(digits = 2) 

# Add a model with predictors and predisposition to pull left
b10.2 <- brm(data = d, family = binomial,
      pulled_left ~ 1 + prosoc_left,
      prior = c(prior(normal(0, 10), class = Intercept), # Intercept
                prior(normal(0, 10), class = b))) # Normal prior
# Update the previous model with interaction based on condition
b10.3 <- update(b10.2,
         newdata = d,
         formula = pulled_left ~ 1 + prosoc_left + condition:prosoc_left)

# B10 should be the best model but with large uncertainty
compare_ic(waic(b10.1),waic(b10.2),waic(b10.3) )
# Look at the model weights
model_weights(b10.1, b10.2, b10.3, weights = "waic")
#-> still some considerable weight for b10.3

# Model averaging
# the combined `fitted()` results of the three models weighted by their WAICs
pp_a <- pp_average(b10.1, b10.2, b10.3,
             weights = "waic",
             method = "fitted") %>%
  as_tibble() %>% 
  bind_cols(b10.3$data) %>% 
  distinct(Estimate, Q2.5, Q97.5, condition, prosoc_left) %>% 
  mutate(x_axis = str_c(prosoc_left, condition, sep = "/")) %>%
  mutate(x_axis = factor(x_axis, levels = c("0/0", "1/0", "0/1", "1/1"))) %>% 
  rename(pulled_left = Estimate)

# the empirically-based summaries
d_plot <-
  d %>%
  group_by(actor, condition, prosoc_left) %>%
  summarise(pulled_left = mean(pulled_left)) %>%
  mutate(x_axis = str_c(prosoc_left, condition, sep = "/")) %>%
  mutate(x_axis = factor(x_axis, levels = c("0/0", "1/0", "0/1", "1/1")))

# Compare
pp_a %>% 
  ggplot(aes(x = x_axis)) +
  geom_ribbon(aes(ymin = Q2.5, 
                  ymax = Q97.5,
                  group = 0),fill="lightblue") +
  geom_line(aes(y = pulled_left,
                group = 0)) +
  geom_line(data = d_plot,
            aes(y = pulled_left, group = actor), size = 1/3) +
  scale_x_discrete(expand = c(.03, .03)) +
  coord_cartesian(ylim = 0:1) +
  labs(x = "prosoc_left/condition",
       y = "proportion pulled left") +
  theme(axis.ticks.x = element_blank())

# Sample from the posterior for model 3
library(bayesplot)
mcmc_pairs(x = posterior_samples(b10.3),
           pars = c("b_Intercept", "b_prosoc_left", "b_prosoc_left:condition"),
           off_diag_args = list(size = 1/10, alpha = 1/6),
           diag_fun = "dens")
# -> Posterior looks multivariate gaussian

# New model that surpresses the default intercept and uses the for each actor
b10.4 <-
  brm(data = d, family = binomial,
      pulled_left ~ 0 + factor(actor) + prosoc_left + condition:prosoc_left ,
      prior(normal(0, 10), class = b), # All prior the same
      iter = 2500, warmup = 500, chains = 2, cores = 2,
      control = list(adapt_delta = 0.9))

post <- posterior_samples(b10.4) # Sample posterior

# Actor 2 intercept. 
post %>% ggplot(aes(x = b_factoractor2)) + geom_density()

# ---------- #
# Aggregated binomial model
d_aggregated <-
  d %>%
  select(-recipient, -block, -trial, -chose_prosoc) %>%
  group_by(actor, condition, prosoc_left) %>%
  summarise(x = sum(pulled_left))

# Aggregated binomial model with the number of trial specified
b10.5 <-
  brm(data = d_aggregated, family = binomial,
      x | trials(18) ~ 1 + prosoc_left + condition:prosoc_left ,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b)),
      iter = 2500, warmup = 500, cores = 2, chains = 2)
# Should be identical to b10.3
fixef(b10.3) %>% round(digits = 2)
fixef(b10.5) %>% round(digits = 2)

# --- #
# Aggregated binomial for school admissions
library(rethinking)
data(UCBadmit)
d <- UCBadmit
detach(package:rethinking)
library(brms)
rm(UCBadmit)

# Male dummy variable
d <-  d %>% mutate(male = ifelse(applicant.gender == "male", 1, 0))

# Does gender has an influence on the admission rate?
b10.6 <-
  brm(data = d, family = binomial,
      admit | trials(applications) ~ 1 + male ,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b)),
      iter = 2500, warmup = 500, cores = 2, chains = 2)

b10.7 <-
  brm(data = d, family = binomial,
      admit | trials(applications) ~ 1,
      prior(normal(0, 10), class = Intercept),
      iter = 2500, warmup = 500, cores = 2, chains = 2)

waic(b10.6, b10.7)

# The relative difference in admission odds
fixef(b10.6)[2] %>% exp() %>%  round(digits = 2)

# Difference in admission probabilities from the posterior
post <- posterior_samples(b10.6)
post %>%
  mutate(p_admit_male   = inv_logit_scaled(b_Intercept + b_male),
         p_admit_female = inv_logit_scaled(b_Intercept),
         diff_admit     = p_admit_male - p_admit_female) %>%
  summarise(`2.5%`  = quantile(diff_admit, probs = .025),
            `50%`   = median(diff_admit),
            `97.5%` = quantile(diff_admit, probs = .975))

# Cases
d <- d %>% mutate(case = factor(1:12))

p_10.6 <-  predict(b10.6) %>%  as_tibble() %>% bind_cols(d)
d_text <- d %>%  group_by(dept) %>%
  summarise(case  = mean(as.numeric(case)),
            admit = mean(admit / applications) + .05)

# Now plot predicted admission difference
ggplot(data = d, aes(x = case, y = admit / applications)) +
  geom_pointrange(data = p_10.6, 
                  aes(y    = Estimate / applications,
                      ymin = Q2.5     / applications ,
                      ymax = Q97.5    / applications),
                  shape = 1, alpha = 1/3) +
  geom_point(color = "red") +
  geom_line(aes(group = dept),
            color = "darkred") +
  geom_text(data = d_text,
            aes(y = admit, label = dept),
            family = "serif") +
  coord_cartesian(ylim = 0:1) +
  labs(y     = "Proportion admitted",
       title = "Posterior validation check") +
  theme(axis.ticks.x = element_blank())



#### LOO  and outlier detection ####
# Leave out criterion
library(loo)
loo(b10.6)
plot(lb10.6 <- loo(b10.6)) # Pareto K can be used to identify overly influential variables on fit
pareto_k_ids(lb10.6, threshold = 1)
lb10.6$diagnostics

# For detecting outliers suing loo
l_b10.6_reloo <- loo(b10.6, reloo = T)
l_b10.7_reloo <- loo(b10.7, reloo = T)
# Also see here
# https://github.com/ASKurz/Student-s-t_regression


# ---------------- #
# Outliers indicate that the above is not really a good fit
# New paradigm:
# “What is the average difference in probability of admission between females and males within departments?

b10.8 <-
  brm(data = d, family = binomial,
      admit | trials(applications) ~ 0 + dept, # No intercept, thus within. Department as beta
      prior(normal(0, 10), class = b),
      iter = 2500, warmup = 500, cores = 2, chains = 2)
# Does gender explain differences?
b10.9 <-update(b10.8,
         newdata = d,
         formula = admit | trials(applications) ~ 0 + dept + male)

# Compare all models
loos <- loo(b10.6, b10.7, b10.8, b10.9, 
            reloo = T,
            cores = 2)

loos
model_weights(b10.6, b10.7, b10.8, b10.9,weights = "loo")
fixef(b10.9) %>% round(digits = 2)
# For proportional odds the posterior mean is 
fixef(b10.9)[7, 1] %>% exp()

# New posterior checkes
predict(b10.9) %>%
  as_tibble() %>% 
  bind_cols(d) %>% 
  ggplot(data = ., aes(x = case, y = admit / applications)) +
  geom_pointrange(data = p_10.6, 
                  aes(y    = Estimate / applications,
                      ymin = Q2.5     / applications ,
                      ymax = Q97.5    / applications),
                  shape = 1, alpha = 1/3) +
  geom_point(color = "red") +
  geom_line(aes(group = dept),
            color = "darkred") +
  geom_text(data = d_text,
            aes(y = admit, label = dept),
            family = "serif") +
  coord_cartesian(ylim = 0:1) +
  labs(y     = "Proportion admitted",
       title = "Posterior validation check") +
  theme(axis.ticks.x = element_blank())


```


#### Poisson distributions and count data ####

```{r Poisson}
library(rethinking)
data(Kline)
d <- Kline
detach(package:rethinking)
library(brms);library(tidyverse)
rm(Kline)

# Log transform and create factor
d <- d %>% mutate(log_pop      = log(population),
                  contact_high = ifelse(contact == "high", 1, 0))

b10.10 <-
  brm(data = d, family = poisson,
      total_tools ~ 1 + log_pop + contact_high + contact_high:log_pop,
      prior = c(prior(normal(0, 100), class = Intercept),
                prior(normal(0, 1), class = b)),
      iter = 3000, warmup = 1000, chains = 4, cores = 4)

# Posterior sample
post <-  posterior_samples(b10.10)

post %>% select(-lp__) %>% rename(b_interaction = `b_log_pop:contact_high`) %>% psych::lowerCor()
library(bayesplot)
post %>% select(-lp__) %>% rename(b_interaction = `b_log_pop:contact_high`) %>%
  mcmc_intervals(prob = .5, prob_outer = .95) +
  theme(axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0))

# How plausible is it a high-contact island will have more tools than a low-contact island?
post <- post %>%
  mutate(lambda_high = exp(b_Intercept + b_contact_high + (b_log_pop + `b_log_pop:contact_high`)*8), # Backtransform
         lambda_low  = exp(b_Intercept + b_log_pop*8)) %>% 
  mutate(diff        = lambda_high - lambda_low) 

post %>%  summarise(sum = sum(diff > 0)/length(diff)) # 95.6 % of all counts
post %>%
  ggplot(aes(x = diff)) +
  geom_density(fill="red",alpha =.6) +
  geom_vline(xintercept = 0, linetype = 2) +
    labs(x = "lambda_high - lambda_low")

# ---- #

# no interaction
b10.11 <- 
  update(b10.10, formula = total_tools ~ 1 + log_pop + contact_high)

# no contact rate
b10.12 <-
  update(b10.10, formula = total_tools ~ 1 + log_pop)

# no log-population
b10.13 <-
  update(b10.10, formula = total_tools ~ 1 + contact_high)

# intercept only
b10.14 <-
  update(b10.10, formula = total_tools ~ 1)

w_b10.10 <- waic(b10.10)
w_b10.11 <- waic(b10.11)
w_b10.12 <- waic(b10.12)
w_b10.13 <- waic(b10.13)
w_b10.14 <- waic(b10.14)

compare_ic(w_b10.10, w_b10.11, w_b10.12, w_b10.13, w_b10.14)

# Do an ensemble posterior prediction
nd <-
  tibble(log_pop      = seq(from = 6.5, to = 13, length.out = 50) %>% 
           rep(., times = 2),
         contact_high = rep(0:1, each = 50))

ppa_10.9 <- 
  pp_average(b10.10, b10.11, b10.12, # The 3 best models
             weights = "loo", # Using loo
             method  = "fitted",
             newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd)

# Plot
ppa_10.9 %>%
  ggplot(aes(x     = log_pop,
             group = contact_high)) +
  geom_ribbon(aes(ymin = Q2.5,
                  ymax = Q97.5,
                  fill = contact_high),
              alpha = 1/4) +
  geom_line(aes(y = Estimate, color = contact_high)) +
  geom_text(data = d, 
             aes(y     = total_tools,
                 label = total_tools,
                 color = contact_high),
             size = 3.5) +
  coord_cartesian(xlim = c(7.1, 12.4),
                  ylim = c(12, 70)) +
  labs(x = "log population",
       y = "total tools",
       subtitle = "Blue is the high contact rate; black is the low.") +
  theme(legend.position = "none",
        panel.border    = element_blank())

# LOO weights
model_weights(b10.10, b10.11, b10.12, 
              weights = "loo")

# ----- #
# Lastly for exposure inclusion
set.seed(3838)

num_days  <- 30
y         <- rpois(num_days, 1.5)
num_weeks <- 4
y_new     <- rpois(num_weeks, 0.5*7)
d <- 
tibble(y         = c(y, y_new), 
       days      = c(rep(1, num_days), rep(7, num_weeks)),
       monastery = c(rep(0, num_days), rep(1, num_weeks))) %>%
mutate(log_days  = log(days))

b10.15 <-
  brm(data = d, family = poisson,
      y ~ 1 + offset(log_days) + monastery, # Specify offset with log days
      prior = c(prior(normal(0, 100), class = Intercept),
                prior(normal(0, 1), class = b)),
      iter = 2500, warmup = 500, cores = 2, chains = 2)

library(tidybayes)

posterior_samples(b10.15) %>%
  transmute(lambda_old = exp(b_Intercept),
            lambda_new = exp(b_Intercept + b_monastery)) %>%
  gather() %>%
  mutate(key = factor(key, levels = c("lambda_old", "lambda_new"))) %>%
  group_by(key) %>%
  mean_hdi(value, .width = .89) %>% 
  mutate_if(is.double, round, digits = 2)

# Leave it there ...


```

<br>

# Monsters and mixture (models) with brms # - 

```{r}
library(rethinking)
data(Trolley)
d <- Trolley

rm(Trolley)
detach(package:rethinking, unload = T)
library(brms)
library(tidyverse)
library(ggthemes)

# Here are our starting values, which we specify with the `inits` argument in brm()
inits <- list(`Intercept[1]` = -2,
              `Intercept[2]` = -1,
              `Intercept[3]` = 0,
              `Intercept[4]` = 1,
              `Intercept[5]` = 2,
              `Intercept[6]` = 2.5)

inits_list <- list(inits, inits)

b11.1 <- 
  brm(data = d, family = cumulative,
      response ~ 1,
      prior(normal(0, 10), class = Intercept),
      iter = 2000, warmup = 1000, cores = 2, chains = 2,
      inits = inits_list)  # Here we add our start values
print(b11.1)

# Get probability metrics
posterior_samples(b11.1) %>% 
  select(starts_with("b_")) %>% # those with an intercept
  mutate_all(inv_logit_scaled) %>%  # inv_log trasnform
  gather() %>% 
  group_by(key) %>% 
  summarise(mean = mean(value),
            sd   = sd(value),
            ll   = quantile(value, probs = .025), # lower limit
            ul   = quantile(value, probs = .975)) # upper limit


# Ordered logistic
# First, we needed to specify the `logistic()` function, which is apart of the `dordlogit()` function
logistic <- function(x) {
    p <- 1 / (1 + exp(-x))
    p <- ifelse(x == Inf, 1, p)
    p
    }

# Function from McElreath book
dordlogit <- 
  function(x, phi, a, log = FALSE) {
    a  <- c(as.numeric(a), Inf)
    p  <- logistic(a[x] - phi)
    na <- c(-Inf, a)
    np <- logistic(na[x] - phi)
    p  <- p - np
    if (log == TRUE) p <- log(p)
    p
    }

# --- #
# Lets fit the model
# Start values for b11.2
inits <- list(`Intercept[1]` = -1.9,
              `Intercept[2]` = -1.2,
              `Intercept[3]` = -0.7,
              `Intercept[4]` =  0.2,
              `Intercept[5]` =  0.9,
              `Intercept[6]` =  1.8,
              action         =  0,
              intention      =  0,
              contact        =  0)

b11.2 <- 
  brm(data = d, family = cumulative,
      response ~ 1 + action + intention + contact,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b)),
      iter = 2000, warmup = 1000, cores = 2, chains = 2,
      inits = list(inits, inits))

# Now with interaction
# Start values for b11.3
inits <- list(`Intercept[1]`      = -1.9,
              `Intercept[2]`      = -1.2,
              `Intercept[3]`      = -0.7,
              `Intercept[4]`      =  0.2,
              `Intercept[5]`      =  0.9,
              `Intercept[6]`      =  1.8,
              action              =  0,
              intention           =  0,
              contact             =  0,
              `action:intention`  =  0,
              `contact:intention` =  0)

b11.3 <- 
  update(b11.2,
         formula = response ~ 1 + action + intention + contact + action:intention + contact:intention,
         inits = list(inits, inits))

library(broom)
tidy(b11.1) %>% mutate(model = "b11.1") %>% 
  bind_rows(tidy(b11.2) %>% mutate(model = "b11.2")) %>% 
  bind_rows(tidy(b11.3) %>% mutate(model = "b11.3")) %>% 
  select(model, term, estimate) %>% 
  filter(term != "lp__") %>% 
  complete(term = distinct(., term), model) %>% 
  mutate(estimate = round(estimate, digits = 2)) %>%
  spread(key = model, value = estimate) %>% 
  # this last step isn't necessary, but it orders the rows to match the text
  slice(c(6:11, 1, 4, 3, 2, 5))

# WAIC comparison
waic(b11.1, b11.2, b11.3) 


```


# The zero inflated things

```{r}
library(tidyverse)
# define parameters
prob_drink <- 0.2  # 20% of days
rate_work  <- 1    # average 1 manuscript per day

# sample one year of production
N <- 365

# simulate days monks drink
set.seed(0.2)
drink <- rbinom(N, 1, prob_drink)

# simulate manuscripts completed
y <- (1 - drink) * rpois(N, rate_work)

d <-
  tibble(Y = y) %>%
  arrange(Y) %>% 
  mutate(zeros = c(rep("zeros_drink", times = sum(drink)),
                   rep("zeros_work",  times = sum(y == 0 & drink == 0)),
                   rep("none",        times = N - sum(y == 0))
                   )) 
# Fit
library(brms)
b11.4 <- 
  brm(data = d, family = zero_inflated_poisson,
      Y ~ 1,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(beta(2, 2), class = zi)),  # the brms default is beta(1, 1)
      cores = 4)

print(b11.4)

```

#### MULTILEVEL MODELS ####

This is the really important bit or rather the most useful bit for most analyses I do.

```{r}
library(rethinking)
data(reedfrogs)
d <- reedfrogs;rm(reedfrogs)
detach(package:rethinking, unload = T)
library(brms)
library(tidyverse)

# Make an id counter
d <- d %>%  mutate(tank = 1:nrow(d))

# Normal Model (pooled):
b12.1 <- brm(data = d, family = binomial,
      surv | trials(density) ~ 0 + factor(tank),
      prior(normal(0, 5), class = b),
      iter = 2000, warmup = 500, chains = 4, cores = 4)
# Each tank gets its own intercept
b12.2 <- brm(data = d, family = binomial,
      surv | trials(density) ~ 1 + (1 | tank),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)), # cauchy prior for varying intercept!
      iter = 4000, warmup = 1000, chains = 4, cores = 4)

waic(b12.1, b12.2)
loo(b12.1, b12.2) # (or use kfold)

# Sample from the posterior
post <- posterior_samples(b12.2)

postMdn <- coef(b12.2, robust = T)$tank[, , ] %>% 
  as_tibble() %>% 
  bind_cols(d) %>%
  mutate(postMdn = inv_logit_scaled(Estimate))
postMdn

library(ggthemes) 
postMdn %>%
  ggplot(aes(x = tank, y = postMdn)) +
  geom_hline(yintercept = inv_logit_scaled(median(post$b_Intercept)), linetype = 2, size = 1/4) +
  geom_vline(xintercept = c(16.5, 32.5), size = 1/4) +
  geom_point(aes(y = propsurv), color = "orange2") +
  geom_point(shape = 1) +
  coord_cartesian(ylim = c(0, 1)) +
  scale_x_continuous(breaks = c(1, 16, 32, 48)) +
  labs(title    = "Multilevel shrinkage!",
       subtitle = "The empirical proportions are in orange while the model-\nimplied proportions are the black circles. The dashed line is\nthe model-implied average survival proportion.") +
  annotate("text", x = c(8, 16 + 8, 32 + 8), y = 0, 
           label = c("small tanks", "medium tanks", "large tanks")) +
  theme_fivethirtyeight() +
  theme(panel.grid = element_blank())

# Also plot the distribution of all estimates
tibble(x = c(-4, 5)) %>%
  ggplot(aes(x = x)) +
  mapply(function(mean, sd) {
    stat_function(fun   = dnorm, 
                  args  = list(mean = mean, sd = sd), 
                  alpha = .2, 
                  color = "orange2")
    }, 
    # Enter means and standard deviations here
    mean = post[1:100, 1],
    sd   = post[1:100, 2]
    ) +
  labs(title = "Population survival distribution",
       subtitle = "The Gaussians are on the log-odds scale.") +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = c(-3, 4)) + 
  theme_fivethirtyeight() +
  theme(plot.title    = element_text(size = 13),
        plot.subtitle = element_text(size = 10))

# Probability of survival
ggplot(data = post, 
       aes(x = rnorm(n    = nrow(post), 
                     mean = post[, 1], 
                     sd   = post[, 2]) %>% 
             inv_logit_scaled())) +
  geom_density(size = 0, fill = "orange2") +
  labs(title = "Probability of survival") +
  scale_y_continuous(NULL, breaks = NULL) +
  theme_fivethirtyeight()

# Stop here(Prior for variance components)

```

#### Varying effects and the underfitting/overfitting trade-off # 

```{r Varying effects}
library(brms)
library(tidyverse)
a       <-  1.4
sigma   <-  1.5
n_ponds <- 60


set.seed(12)
(
  dsim <- 
  tibble(pond   = 1:n_ponds,
         ni     = rep(c(5, 10, 25, 35), each = n_ponds / 4) %>% as.integer(),
         true_a = rnorm(n = n_ponds, mean = a, sd = sigma))
  )

set.seed(12)
(
  dsim <-
  dsim %>%
  mutate(si = rbinom(n = n(), prob = inv_logit_scaled(true_a), size = ni))
  )

# No pooling estimates
(
  dsim <-
  dsim %>%
  mutate(p_nopool = si / ni)
  )


## Calculate partial pooling estimates ##

b12.3 <- 
  brm(data = dsim, family = binomial,
      si | trials(ni) ~ 1 + (1 | pond),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)),
      iter = 10000, warmup = 1000, chains = 1, cores = 1,
      seed = 12)

coef(b12.3)$pond[c(1:2, 59:60), , ] %>%  round(digits = 2)

# And calculate effective sample ratio
(n_iter <- (b12.3$fit@sim$iter - b12.3$fit@sim$warmup) * b12.3$fit@sim$chains)

neff_ratio(b12.3) %>% 
  data.frame() %>% 
  rownames_to_column() %>% 
  set_names("parameter", "neff_ratio") %>% 
  mutate(eff_sample = (neff_ratio * n_iter) %>% round(digits = 0)) %>% 
  head()

# Start to construct figure # 
p_partpool <- 
  coef(b12.3)$pond[, , ] %>% 
  as_tibble() %>%
  transmute(p_partpool = inv_logit_scaled(Estimate))

dsim <- 
  dsim %>%
  bind_cols(p_partpool) %>% 
  mutate(p_true         = inv_logit_scaled(true_a)) %>%
  mutate(nopool_error   = abs(p_nopool   - p_true),
         partpool_error = abs(p_partpool - p_true))

dfline <- 
  dsim %>%
  select(ni, nopool_error:partpool_error) %>%
  gather(key, value, -ni) %>%
  group_by(key, ni) %>%
  summarise(mean_error = mean(value)) %>%
  mutate(x    = c( 1, 16, 31, 46),
         xend = c(15, 30, 45, 60))

#
library(ggplot2)
library(ggthemes)

dsim %>% 
  ggplot(aes(x = pond)) +
  geom_vline(xintercept = c(15.5, 30.5, 45.4), 
             color = "white", size = 2/3) +
  geom_point(aes(y = nopool_error), color = "orange2") +
  geom_point(aes(y = partpool_error), shape = 1) +
  geom_segment(data = dfline, 
               aes(x = x, xend = xend, 
                   y = mean_error, yend = mean_error),
               color = rep(c("orange2", "black"), each = 4),
               linetype = rep(1:2, each = 4)) +
  scale_x_continuous(breaks = c(1, 10, 20, 30, 40, 50, 60)) +
  annotate("text", x = c(15 - 7.5, 30 - 7.5, 45 - 7.5, 60 - 7.5), y = .45, 
           label = c("tiny (5)", "small (10)", "medium (25)", "large (35)")) +
  labs(y        = "absolute error",
       title    = "Estimate error by model type",
       subtitle = "The horizontal axis displays pond number. The vertical axis measures\nthe absolute error in the predicted proportion of survivors, compared to\nthe true value used in the simulation. The higher the point, the worse\nthe estimate. No-pooling shown in orange. Partial pooling shown in black.\nThe orange and dashed black lines show the average error for each kind\nof estimate, across each initial density of tadpoles (pond size). Smaller\nponds produce more error, but the partial pooling estimates are better\non average, especially in smaller ponds.") +
  theme_fivethirtyeight() +
  theme(panel.grid    = element_blank(),
        plot.subtitle = element_text(size = 10))

```


```{r Multiple clusters}
library(rethinking)
data(chimpanzees)
d <- chimpanzees
rm(chimpanzees)
detach(package:rethinking, unload = T)
library(brms)

# Varying intercepts for actor but not block
b12.4 <- 
  brm(data = d, family = binomial,
      pulled_left | trials(1) ~ 1 + prosoc_left + prosoc_left:condition + (1 | actor),
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(cauchy(0, 1), class = sd)),
      # I'm using 4 cores, instead of the `cores=3` in McElreath's code
      iter = 5000, warmup = 1000, chains = 4, cores = 4,  
      control = list(adapt_delta = 0.95),
      seed = 12)

# To get the results
post <- posterior_samples(b12.4)

post %>%
  select(starts_with("r_actor")) %>% 
  gather() %>%
  # this is how we might add the grand mean to the actor-level deviations
  mutate(value = value + post$b_Intercept) %>% 
  group_by(key) %>%
  summarise(mean = mean(value) %>% round(digits = 2))

b12.5 <- 
  update(b12.4,
         newdata = d,
         formula = pulled_left | trials(1) ~ 1 + prosoc_left + prosoc_left:condition + 
           (1 | actor) + (1 | block),
         iter = 6000, warmup = 1000, cores = 4, chains = 4, 
         control = list(adapt_delta = 0.99),
         seed = 12)

library(bayesplot)
# Luckily none under the threshold of 0.1
neff_ratio(b12.5) %>% 
  mcmc_neff()

# Plot coefficients
stanplot(b12.5, pars = c("^r_", "^b_", "^sd_")) +
  theme_fivethirtyeight() +
  theme(axis.text.y = element_text(hjust = 0))

# And to compare LOO estimates
b12.4 <- add_criterion(b12.4, "loo")
b12.5 <- add_criterion(b12.5, "loo")

loo_compare(b12.4, b12.5) %>% 
  print(simplify = F)

```


Next lets have a look at multilevel posterior predictions

```{r Posterior prediction for same clusters}

chimp <- 2
nd <-
  tibble(prosoc_left = c(0, 1, 0, 1),
         condition   = c(0, 0, 1, 1),
         actor       = chimp)


(
  chimp_2_fitted <-
  fitted(b12.4,
         newdata = nd) %>% 
  as_tibble() %>% 
  mutate(condition = factor(c("0/0", "1/0", "0/1", "1/1"), 
                            levels = c("0/0", "1/0", "0/1", "1/1")))
  )

(
  chimp_2_d <-
  d %>% 
  filter(actor == chimp) %>% 
  group_by(prosoc_left, condition) %>% 
  summarise(prob = mean(pulled_left)) %>% 
  ungroup() %>% 
  mutate(condition = str_c(prosoc_left, "/", condition)) %>% 
  mutate(condition = factor(condition, levels = c("0/0", "1/0", "0/1", "1/1")))
)

# The plot
chimp_2_fitted %>%
  # if you want to use `geom_line()` or `geom_ribbon()` with a factor on the x axis,
  # you need to code something like `group = 1` in `aes()`
  ggplot(aes(x = condition, y = Estimate, group = 1)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), fill = "orange1") +
  geom_line(color = "blue") +
  geom_point(data = chimp_2_d,
             aes(y = prob),
             color = "grey25") +
  ggtitle("Chimp #2",
          subtitle = "The posterior mean and 95%\nintervals are the blue line\nand orange band, respectively.\nThe empirical means are\nthe charcoal dots.") +
  coord_cartesian(ylim = c(.75, 1)) +
  theme_fivethirtyeight() +
  theme(plot.subtitle = element_text(size = 10))


```

```{r Posterior predictions for new clusters}

post_average_actor <-
  post %>% 
  # here we use the linear regression formula to get the log_odds for the 4 conditions
  transmute(`0/0` = b_Intercept,
            `1/0` = b_Intercept + b_prosoc_left,
            `0/1` = b_Intercept,
            `1/1` = b_Intercept + b_prosoc_left + `b_prosoc_left:condition`) %>%
  # with `mutate_all()` we can convert the estimates to probabilities in one fell swoop
  mutate_all(inv_logit_scaled) %>% 
  # putting the data in the long format and grouping by condition (i.e., `key`)
  gather() %>%
  mutate(key = factor(key, level = c("0/0", "1/0", "0/1", "1/1"))) %>% 
  group_by(key) %>%
  # here we get the summary values for the plot
  summarise(m  = mean(value),
            # note we're using 80% intervals
            ll = quantile(value, probs = .1),
            ul = quantile(value, probs = .9))

p1 <-
  post_average_actor %>%
  ggplot(aes(x = key, y = m, group = 1)) +
  geom_ribbon(aes(ymin = ll, ymax = ul), fill = "orange1") +
  geom_line(color = "blue") +
  ggtitle("Average actor") +
  coord_cartesian(ylim = 0:1) +
  theme_fivethirtyeight() +
  theme(plot.title = element_text(size = 14, hjust = .5))
p1

# the random effects
set.seed(12.42)
ran_ef <-
  tibble(random_effect = rnorm(n = 1000, mean = 0, sd = post$sd_actor__Intercept)) %>% 
  # with the `., ., ., .` syntax, we quadruple the previous line 
  bind_rows(., ., ., .)

# the fixed effects (i.e., the population parameters)
fix_ef <-
  post %>% 
  slice(1:1000) %>%
  transmute(`0/0` = b_Intercept,
            `1/0` = b_Intercept + b_prosoc_left,
            `0/1` = b_Intercept,
            `1/1` = b_Intercept + b_prosoc_left + `b_prosoc_left:condition`) %>%
  gather() %>%
  rename(condition    = key, 
         fixed_effect = value) %>% 
  mutate(condition = factor(condition, level = c("0/0", "1/0", "0/1", "1/1")))

# combine them
ran_and_fix_ef <-
  bind_cols(ran_ef, fix_ef) %>%
  mutate(intercept = fixed_effect + random_effect) %>%
  mutate(prob      = inv_logit_scaled(intercept))


# to simplify things, we'll reduce them to summaries
(
  marginal_effects <-
  ran_and_fix_ef %>%
  group_by(condition) %>%
  summarise(m  = mean(prob),
            ll = quantile(prob, probs = .1),
            ul = quantile(prob, probs = .9))
  )

p2 <-
  marginal_effects %>%
  ggplot(aes(x = condition, y = m, group = 1)) +
  geom_ribbon(aes(ymin = ll, ymax = ul), fill = "orange1") +
  geom_line(color = "blue") +
  ggtitle("Marginal of actor") +
  coord_cartesian(ylim = 0:1) +
  theme_fivethirtyeight() +
  theme(plot.title = element_text(size = 14, hjust = .5))
p2

# 50 simulated actors
p3 <-
  ran_and_fix_ef %>%
  mutate(iter = rep(1:1000, times = 4)) %>%
  filter(iter %in% c(1:50)) %>%
  
  ggplot(aes(x = condition, y = prob, group = iter)) +
  theme_fivethirtyeight() +
  ggtitle("50 simulated actors") +
  coord_cartesian(ylim = 0:1) +
  geom_line(alpha = 1/2, color = "orange3") +
  theme(plot.title = element_text(size = 14, hjust = .5))
p3
gridExtra::grid.arrange(p1, p2, p3, ncol = 3)


```
