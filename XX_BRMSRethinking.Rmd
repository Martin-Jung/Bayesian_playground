---
title: "Rethinking with BRMS"
output: html_notebook
---

# Bayesian models with BRMS

Redoing some of the Rethinking book with the *tidyverse* and *brms* package. [https://bookdown.org/content/1850/index.html](Tutorial and code here.)
Mainly using MCMC via Stan and the *brms* package. Idea is to redo some of the examples by McElreath but with brms or stan directly.

Load all necessary packages
```{r,echo=FALSE,message=FALSE, warning=FALSE, include=FALSE}
source("00_PackagesFunctions.R")
```

# Prior recommendations from the [https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations](stan project).

## Stan

Avoid using uniform priors!
You think a parameter could be anywhere from 0 to 1, so you set the prior to uniform(0,1). Try normal(.5,.5) instead.

## Aim to keep all parameters scale-free. Many ways of doing this:

* Scale by sd of data. This is done in education settings, here the sd is the sd of test scores of all kids in a single grade, for example
*  In a regression, take logs of (positive-constrained) predictors and outcomes, then coefs can be interpreted as elasticities
*  Scale by some conventional value, for example if a parameter has a "typical" value of 4.5, you could work with log(theta/4.5). We did some things like this in our PK/PD project with Sebastian1. For example, in epidemiological studies it is common to standardize with the expected number of events.

Keep paremeters scale free. Divide by SD or better MAD

<hr>
Code start

```{r}
# The first model from McElReath
b3.1 <- brm(data = list(w = 6), 
      family = binomial(link = "identity"),
      w | trials(9) ~ 1,
      prior = prior(beta(1, 1), class = Intercept),
      control = list(adapt_delta = .99))

posterior_summary(b3.1)["b_Intercept", ] %>% round(digits = 2)

# Get simulation draws instead
fitted_samples <- fitted(b3.1, summary = F, scale = "linear") %>%   as_tibble()

```

# Chapter 4 - Linear models

```{r}
library(rethinking)
data(Howell1)
d <- Howell1
detach(package:rethinking,unload = T)

# Linear model with brms
d2 <- d %>% filter(age >= 18)

b4.1 <- brm(data = d2, family = gaussian,
      height ~ 1, # Intercept only model
      prior = c(prior(normal(178, 20), class = Intercept), # mu
                prior(uniform(0, 50), class = sigma)), # sd
      iter = 31000, warmup = 30000, chains = 4, cores = 4)

# Repeat but with a cauchy prior
b4.1_half_cauchy <- brm(data = d2, family = gaussian,
      height ~ 1,
      prior = c(prior(normal(178, 20), class = Intercept),
                prior(cauchy(0, 1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4)

# Inspect the chains
plot(b4.1_half_cauchy)
# Or via shiny interface
launch_shinystan(b4.1_half_cauchy)
b4.1_half_cauchy$fit

# Covariance of brms object
post <- posterior_samples(b4.1_half_cauchy)
cov(post[, 1:2])

# Or other ways of summarising:
posterior_summary(b4.1_half_cauchy)


```
-

```{r}
# Multiple linear regression - 4.4.2
b4.3 <- brm(data = d2, family = gaussian,
      height ~ 1 + weight,
      prior = c(prior(normal(156, 100), class = Intercept), # prior for intercep
                prior(normal(0, 10), class = b), # for beta
                #prior(uniform(0, 50), class = sigma)), # for sigma
                prior(cauchy(0,1), class = sigma)), # cauchy uses less warmup
      iter = 41000, warmup = 40000, chains = 4, cores = 4)

# Center and refit (with cauchy prior)
d2$weight.c <- d2$weight - mean(d2$weight,na.rm = T)

b4.4 <- brm(data = d2, family = gaussian,
      height ~ 1 + weight.c,
      prior = c(prior(normal(178, 100), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(cauchy(0, 1), class = sigma)),
      iter = 46000, warmup = 45000, chains = 4, cores = 4,
      control = list(adapt_delta = 0.8, 
                     max_treedepth = 10))

plot(b4.4) # Check
posterior_summary(b4.4)[1:3, ] # Summarise
#pairs(b4.4)


post <- posterior_samples(b4.3)
# Mean at 50
mu_at_50 <- post %>% transmute(mu_at_50 = b_Intercept + b_weight * 50)
mu_at_50 %>%
  ggplot(aes(x = mu_at_50)) +
  geom_density(size = 0, fill = "royalblue") +
  stat_pointintervalh(aes(y = 0), 
                      point_interval = mode_hdi, .width = .95) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(x = expression(mu["height | weight = 50"])) +
  theme_classic()


# Plot quick regression line and fit uncertainty of mu using brms
weight_seq <- tibble(weight = seq(from = 25, to = 70, by = 1)) # Predata
mu_summary <-fitted(b4.3, 
         newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq)

d2 %>%
  ggplot(aes(x = weight, y = height)) +
  geom_ribbon(data = mu_summary, 
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              fill = "grey70") +
  geom_line(data = mu_summary, 
            aes(y = Estimate)) +
  geom_point(color = "navyblue", shape = 1, size = 1.5, alpha = 2/3) +
  coord_cartesian(xlim = range(d2$weight)) +
  theme(text = element_text(family = "Arial"),
        panel.grid = element_blank())

# ...these simulations (predictions) are the joint consequence of both μ and σ, unlike the results of fitted(), which only reflect μ. 
pred_height <-  predict(b4.3,newdata = weight_seq) %>%
  as_tibble() %>%
  bind_cols(weight_seq)
  
d2 %>%
  ggplot(aes(x = weight)) +
  geom_ribbon(data = pred_height, 
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              fill = "grey83") +
  geom_ribbon(data = mu_summary, 
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              fill = "grey70") +
  geom_line(data = mu_summary, aes(y = Estimate)) +
  geom_point(aes(y = height),
             color = "navyblue", shape = 1, size = 1.5, alpha = 2/3) +
  coord_cartesian(xlim = range(d2$weight),
                  ylim = range(d2$height)) +
  theme(text = element_text(family = "Arial"),
        panel.grid = element_blank())

```

# For chapter 5 - Multivariate linear models

```{r}
rm(list = ls());gc() # Cleanup
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
rm(WaffleDivorce)
detach(package:rethinking, unload = T)

# -------------------- #
# Standardize
d <-d %>%
  mutate(MedianAgeMarriage_s = (MedianAgeMarriage - mean(MedianAgeMarriage)) /
           sd(MedianAgeMarriage))

b5.1 <- 
  brm(data = d, family = gaussian,
      Divorce ~ 1 + MedianAgeMarriage_s,
      prior = c(prior(normal(10, 10), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(uniform(0, 10), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4)
b5.1
# Plot
nd <- tibble(MedianAgeMarriage_s = seq(from = -3, to = 3.5, length.out = 30))

# Now use `fitted()` to get the model-implied trajectories
fitd_b5.1 <- 
  fitted(b5.1, newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd)

# Plot
ggplot(data = fitd_b5.1, 
       aes(x = MedianAgeMarriage_s, y = Estimate)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              fill = "firebrick", alpha = 1/5) +
  geom_line(color = "firebrick4") +
  geom_point(data = d, 
             aes(x = MedianAgeMarriage_s, y = Divorce), 
             size = 2, color = "firebrick4") +
  labs(y = "Divorce") +
  coord_cartesian(xlim = range(d$MedianAgeMarriage_s), 
                  ylim = range(d$Divorce)) +
  theme_bw() +
  theme(panel.grid = element_blank())                   

```

Multivariate model

```{r}
d <- d %>% mutate(Marriage_s = (Marriage - mean(Marriage)) / sd(Marriage))

b5.3 <- 
  brm(data = d, family = gaussian,
      Divorce ~ 1 + Marriage_s + MedianAgeMarriage_s,
      prior = c(prior(normal(10, 10), class = Intercept),
                prior(normal(0, 1), class = b),
                prior(uniform(0, 10), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4)

stanplot(b5.3)
# Can also plot using bayes plot (draw from posterior first)
# or using the tidybayes package

library(tidybayes)
post <- posterior_samples(b5.3)

post %>% 
  select(-lp__) %>% 
  gather() %>% 
  
  ggplot(aes(x = value, y = reorder(key, value))) +  # note how we used `reorder()` to arrange the coefficients
  geom_vline(xintercept = 0, color = "firebrick4", alpha = 1/10) +
  geom_halfeyeh(point_interval = mode_hdi, .width = .95, 
                      size = 3/4, color = "firebrick4",fill="grey80") +
  labs(title = "My tidybayes-based coefficient plot",
       x = NULL, y = NULL) +
  theme_bw() +
  theme(panel.grid   = element_blank(),
        panel.grid.major.y = element_line(color = alpha("firebrick4", 1/4), linetype = 3),
        axis.text.y  = element_text(hjust = 0),
        axis.ticks.y = element_blank())

# Generally
tibble(`brms function` = c("fitted", "predict", "residual"),
       mean  = c("same as the data", "same as the data", "in a deviance-score metric"),
       scale = c("excludes sigma", "includes sigma", "excludes sigma"))



```


# Skipping some. Moving on with categorical variables

```{r}
rm(list = ls())
library(rethinking)
data(Howell1)
d <- Howell1
rm(Howell1)
detach(package:rethinking, unload = T)

b5.15 <- brm(data = d, family = gaussian,
      height ~ 1 + male,
      prior = c(prior(normal(178, 100), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(cauchy(0, 2), class = sigma)),
      iter = 2000, warmup = 500, chains = 4, cores = 4)
print(b5.15)

fitted(b5.15,    newdata = data.frame(male = c(0,1)))
```

<hr>

# Chapter 6
```{r Overfitting}

sppnames <- c( "afarensis","africanus","habilis","boisei", "rudolfensis","ergaster","sapiens")
brainvolcc <- c( 438 , 452 , 612, 521, 752, 871, 1350 )
masskg <- c( 37.0 , 35.5 , 34.5 , 41.5 , 55.5 , 61.0 , 53.5 )
d <- data.frame( species=sppnames , brain=brainvolcc , mass=masskg ) %>% 
  # Standardize Mass
  mutate(mass_s = (mass - mean(mass)) / sd(mass))

# Here we specify our starting values
inits <- list(Intercept = mean(d$brain), # Intercept as mean
              mass_s    = 0, # mass 0
              sigma     = sd(d$brain)) # uncertainty to sd

# Need as many lists as MCMC chains 
# -> Could mix starting values among chains
inits_list <-list(inits, inits, inits, inits)

# The model
b6.8 <- 
  brm(data = d, family = gaussian,
      brain ~ 1 + mass_s,
      prior = c(prior(normal(0, 1000), class = Intercept),
                prior(normal(0, 1000), class = b),
                prior(cauchy(0, 10), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      inits = inits_list)  # Here we put our start values in the `brm()` function
b6.8

# Loglik per HMC iteration
dfLL <- b6.8 %>%
  log_lik() %>%
  as_tibble() %>% 
  # Deviance as sum of likelihood multiplied by -2
  mutate(sums  = rowSums(.),
         deviance = -2*sums)

# Plot deviance
dfLL %>%
  ggplot(aes(x = deviance, y = 0)) +
  geom_halfeyeh(point_interval = median_qi, .width = .95) +
  scale_x_continuous(breaks = quantile(dfLL$deviance, c(.025, .5, .975)),
                     labels = quantile(dfLL$deviance, c(.025, .5, .975)) %>% round(1)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "The deviance distribution") +
  theme_classic() 

```

The WAIC with brms is straight forward for both model comparison and model averaging, however loo seems to be prefered these days

```{r}
library(rethinking)
data(milk)

d <- milk %>%
  filter(complete.cases(.)) %>%
  mutate(neocortex = neocortex.perc / 100)
rm(milk)

detach(package:rethinking, unload = T)
library(brms)

# Initialize with mean and standard deviation
inits <- list(Intercept = mean(d$kcal.per.g),
              sigma     = sd(d$kcal.per.g))

inits_list <-list(inits, inits, inits, inits)

b6.11 <- brm(data = d, family = gaussian,
      kcal.per.g ~ 1, # Intercept only
      prior = c(prior(uniform(-1000, 1000), class = Intercept), # Very uninformative priors
                prior(uniform(0, 100), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      inits = inits_list)

# Second model. Regress agains neocortex
inits <- list(Intercept = mean(d$kcal.per.g),
              neocortex = 0,
              sigma     = sd(d$kcal.per.g))
b6.12 <- brm(data = d, family = gaussian,
      kcal.per.g ~ 1 + neocortex,
      prior = c(prior(uniform(-1000, 1000), class = Intercept),
                prior(uniform(-1000, 1000), class = b),
                prior(uniform(0, 100), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      inits = inits_list)

# Then create some secondary models by updating them
inits <- list(Intercept   = mean(d$kcal.per.g),
              `log(mass)` = 0,
              sigma       = sd(d$kcal.per.g))

b6.13 <-update(b6.12, 
         newdata = d,
         formula = kcal.per.g ~ 1 + log(mass),
         inits   = inits_list)

# Lastly
inits <- list(Intercept   = mean(d$kcal.per.g),
              neocortex   = 0,
              `log(mass)` = 0,
              sigma       = sd(d$kcal.per.g))
b6.14 <- update(b6.13, 
         newdata = d,
         formula = kcal.per.g ~ 1 + neocortex + log(mass),
         inits   = inits_list)

# Compare all
waic(b6.11, b6.12, b6.13, b6.14)
# Model weights
model_weights(b6.11, b6.12, b6.13, b6.14, weights = "waic")

LOO(b6.14)# The LOO

# Averaged parameters across best models
posterior_average(b6.13,b6.14, weights = "waic")

# Now construct a model average model
# we need new data for both the `fitted()` and `pp_average()` functions
nd <- tibble(neocortex = seq(from = .5, to = .8, length.out = 30),
         mass = rep(4.5, times = 30))

# we'll get the `b6.14`-implied trajectory with `fitted()`
fitd_b6.14 <- fitted(b6.14, newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd)

# the model-average trajectory comes from `pp_average()`
pp_average(b6.11, b6.12, b6.13, b6.14,
           weights = "waic",
           method  = "fitted",  # for new data predictions, use `method = "predict"`
           newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd) %>%
  
  # plot Figure 
ggplot(aes(x = neocortex, y = Estimate)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 1/4) +
  geom_line(color   = "red") +
  geom_ribbon(data  = fitd_b6.14, aes(ymin = Q2.5, ymax = Q97.5),
              color = "grey80", fill = "transparent", linetype = 2) +
  geom_line(data = fitd_b6.14, linetype = 2) +
  geom_point(data = d, aes(x = neocortex, y = kcal.per.g), 
             size = 2) +
  labs(y = "kcal.per.g") +
  coord_cartesian(xlim = range(d$neocortex), 
                  ylim = range(d$kcal.per.g)) +
  theme_gray() 


# ----- #
# Bayesian R2
bayes_R2(b6.14)

# Plot marginal effects
plot(marginal_effects(b6.14,
                      spaghetti = T, nsamples = 200),
     points = T,
     point_args = c(alpha = 1/2, size = 1))

```

#
- Chapter 8 is pretty much self explanatory

- Same with 9. Reading through examples there...
But lets fit a distributional mode

```{r}
set.seed(100)
(
  d <-
  tibble(x = rep(0:1, each = 100)) %>% 
  mutate(y = rnorm(n = n(), mean = 100, sd = 10 + x * 10))
  )


d %>% 
  mutate(x = x %>% as.character()) %>% 
  ggplot(aes(x = y, y = x, fill = x)) +
  geom_halfeyeh(point_interval = mean_qi, .width = .68) 
# Both are identical in the mean but differ in the variation

# In berms
b9.1 <- 
  brm(data = d, 
      family = gaussian,
      bf(y ~ 1, sigma ~ 1 + x), # Two formulas! One for mean, one for sigma
      prior = c(prior(normal(100, 10), class = Intercept),
                prior(normal(0, 10),   class = Intercept, dpar = sigma), # dpar for sigma
                prior(normal(0, 10),   class = b,         dpar = sigma)))
print(b9.1)

```

# Chapter 10


```{r Bionomial models}

library(rethinking)
data(chimpanzees)
d <- chimpanzees
library(brms);library(tidyverse)
rm(chimpanzees)

# Intercept only logistic model
b10.1 <-brm(data = d, family = binomial,
      pulled_left ~ 1,
      prior(normal(0, 10), class = Intercept))

# Get intercept only estimates and backtransform
fixef(b10.1) %>% inv_logit_scaled() %>% round(digits = 2) 

# Add a model with predictors and predisposition to pull left
b10.2 <- brm(data = d, family = binomial,
      pulled_left ~ 1 + prosoc_left,
      prior = c(prior(normal(0, 10), class = Intercept), # Intercept
                prior(normal(0, 10), class = b))) # Normal prior
# Update the previous model with interaction based on condition
b10.3 <- update(b10.2,
         newdata = d,
         formula = pulled_left ~ 1 + prosoc_left + condition:prosoc_left)

# B10 should be the best model but with large uncertainty
compare_ic(waic(b10.1),waic(b10.2),waic(b10.3) )
# Look at the model weights
model_weights(b10.1, b10.2, b10.3, weights = "waic")
#-> still some considerable weight for b10.3

# Model averaging
# the combined `fitted()` results of the three models weighted by their WAICs
pp_a <- pp_average(b10.1, b10.2, b10.3,
             weights = "waic",
             method = "fitted") %>%
  as_tibble() %>% 
  bind_cols(b10.3$data) %>% 
  distinct(Estimate, Q2.5, Q97.5, condition, prosoc_left) %>% 
  mutate(x_axis = str_c(prosoc_left, condition, sep = "/")) %>%
  mutate(x_axis = factor(x_axis, levels = c("0/0", "1/0", "0/1", "1/1"))) %>% 
  rename(pulled_left = Estimate)

# the empirically-based summaries
d_plot <-
  d %>%
  group_by(actor, condition, prosoc_left) %>%
  summarise(pulled_left = mean(pulled_left)) %>%
  mutate(x_axis = str_c(prosoc_left, condition, sep = "/")) %>%
  mutate(x_axis = factor(x_axis, levels = c("0/0", "1/0", "0/1", "1/1")))

# Compare
pp_a %>% 
  ggplot(aes(x = x_axis)) +
  geom_ribbon(aes(ymin = Q2.5, 
                  ymax = Q97.5,
                  group = 0),fill="lightblue") +
  geom_line(aes(y = pulled_left,
                group = 0)) +
  geom_line(data = d_plot,
            aes(y = pulled_left, group = actor), size = 1/3) +
  scale_x_discrete(expand = c(.03, .03)) +
  coord_cartesian(ylim = 0:1) +
  labs(x = "prosoc_left/condition",
       y = "proportion pulled left") +
  theme(axis.ticks.x = element_blank())

# Sample from the posterior for model 3
library(bayesplot)
mcmc_pairs(x = posterior_samples(b10.3),
           pars = c("b_Intercept", "b_prosoc_left", "b_prosoc_left:condition"),
           off_diag_args = list(size = 1/10, alpha = 1/6),
           diag_fun = "dens")
# -> Posterior looks multivariate gaussian

# New model that surpresses the default intercept and uses the for each actor
b10.4 <-
  brm(data = d, family = binomial,
      pulled_left ~ 0 + factor(actor) + prosoc_left + condition:prosoc_left ,
      prior(normal(0, 10), class = b), # All prior the same
      iter = 2500, warmup = 500, chains = 2, cores = 2,
      control = list(adapt_delta = 0.9))

post <- posterior_samples(b10.4) # Sample posterior

# Actor 2 intercept. 
post %>% ggplot(aes(x = b_factoractor2)) + geom_density()

# ---------- #
# Aggregated binomial model
d_aggregated <-
  d %>%
  select(-recipient, -block, -trial, -chose_prosoc) %>%
  group_by(actor, condition, prosoc_left) %>%
  summarise(x = sum(pulled_left))

# Aggregated binomial model with the number of trial specified
b10.5 <-
  brm(data = d_aggregated, family = binomial,
      x | trials(18) ~ 1 + prosoc_left + condition:prosoc_left ,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b)),
      iter = 2500, warmup = 500, cores = 2, chains = 2)
# Should be identical to b10.3
fixef(b10.3) %>% round(digits = 2)
fixef(b10.5) %>% round(digits = 2)

# --- #
# Aggregated binomial for school admissions
library(rethinking)
data(UCBadmit)
d <- UCBadmit
detach(package:rethinking)
library(brms)
rm(UCBadmit)

# Male dummy variable
d <-  d %>% mutate(male = ifelse(applicant.gender == "male", 1, 0))

# Does gender has an influence on the admission rate?
b10.6 <-
  brm(data = d, family = binomial,
      admit | trials(applications) ~ 1 + male ,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b)),
      iter = 2500, warmup = 500, cores = 2, chains = 2)

b10.7 <-
  brm(data = d, family = binomial,
      admit | trials(applications) ~ 1,
      prior(normal(0, 10), class = Intercept),
      iter = 2500, warmup = 500, cores = 2, chains = 2)

waic(b10.6, b10.7)

# The relative difference in admission odds
fixef(b10.6)[2] %>% exp() %>%  round(digits = 2)

# Difference in admission probabilities from the posterior
post <- posterior_samples(b10.6)
post %>%
  mutate(p_admit_male   = inv_logit_scaled(b_Intercept + b_male),
         p_admit_female = inv_logit_scaled(b_Intercept),
         diff_admit     = p_admit_male - p_admit_female) %>%
  summarise(`2.5%`  = quantile(diff_admit, probs = .025),
            `50%`   = median(diff_admit),
            `97.5%` = quantile(diff_admit, probs = .975))

# Cases
d <- d %>% mutate(case = factor(1:12))

p_10.6 <-  predict(b10.6) %>%  as_tibble() %>% bind_cols(d)
d_text <- d %>%  group_by(dept) %>%
  summarise(case  = mean(as.numeric(case)),
            admit = mean(admit / applications) + .05)

# Now plot predicted admission difference
ggplot(data = d, aes(x = case, y = admit / applications)) +
  geom_pointrange(data = p_10.6, 
                  aes(y    = Estimate / applications,
                      ymin = Q2.5     / applications ,
                      ymax = Q97.5    / applications),
                  shape = 1, alpha = 1/3) +
  geom_point(color = "red") +
  geom_line(aes(group = dept),
            color = "darkred") +
  geom_text(data = d_text,
            aes(y = admit, label = dept),
            family = "serif") +
  coord_cartesian(ylim = 0:1) +
  labs(y     = "Proportion admitted",
       title = "Posterior validation check") +
  theme(axis.ticks.x = element_blank())



#### LOO  and outlier detection ####
# Leave out criterion
library(loo)
loo(b10.6)
plot(lb10.6 <- loo(b10.6)) # Pareto K can be used to identify overly influential variables on fit
pareto_k_ids(lb10.6, threshold = 1)
lb10.6$diagnostics

# For detecting outliers suing loo
l_b10.6_reloo <- loo(b10.6, reloo = T)
l_b10.7_reloo <- loo(b10.7, reloo = T)
# Also see here
# https://github.com/ASKurz/Student-s-t_regression


# ---------------- #
# Outliers indicate that the above is not really a good fit
# New paradigm:
# “What is the average difference in probability of admission between females and males within departments?

b10.8 <-
  brm(data = d, family = binomial,
      admit | trials(applications) ~ 0 + dept, # No intercept, thus within. Department as beta
      prior(normal(0, 10), class = b),
      iter = 2500, warmup = 500, cores = 2, chains = 2)
# Does gender explain differences?
b10.9 <-update(b10.8,
         newdata = d,
         formula = admit | trials(applications) ~ 0 + dept + male)

# Compare all models
loos <- loo(b10.6, b10.7, b10.8, b10.9, 
            reloo = T,
            cores = 2)

loos
model_weights(b10.6, b10.7, b10.8, b10.9,weights = "loo")
fixef(b10.9) %>% round(digits = 2)
# For proportional odds the posterior mean is 
fixef(b10.9)[7, 1] %>% exp()

# New posterior checkes
predict(b10.9) %>%
  as_tibble() %>% 
  bind_cols(d) %>% 
  ggplot(data = ., aes(x = case, y = admit / applications)) +
  geom_pointrange(data = p_10.6, 
                  aes(y    = Estimate / applications,
                      ymin = Q2.5     / applications ,
                      ymax = Q97.5    / applications),
                  shape = 1, alpha = 1/3) +
  geom_point(color = "red") +
  geom_line(aes(group = dept),
            color = "darkred") +
  geom_text(data = d_text,
            aes(y = admit, label = dept),
            family = "serif") +
  coord_cartesian(ylim = 0:1) +
  labs(y     = "Proportion admitted",
       title = "Posterior validation check") +
  theme(axis.ticks.x = element_blank())


```


#### Poisson distributions and count data ####

```{r Poisson}
library(rethinking)
data(Kline)
d <- Kline
detach(package:rethinking)
library(brms);library(tidyverse)
rm(Kline)

# Log transform and create factor
d <- d %>% mutate(log_pop      = log(population),
                  contact_high = ifelse(contact == "high", 1, 0))

b10.10 <-
  brm(data = d, family = poisson,
      total_tools ~ 1 + log_pop + contact_high + contact_high:log_pop,
      prior = c(prior(normal(0, 100), class = Intercept),
                prior(normal(0, 1), class = b)),
      iter = 3000, warmup = 1000, chains = 4, cores = 4)

# Posterior sample
post <-  posterior_samples(b10.10)

post %>% select(-lp__) %>% rename(b_interaction = `b_log_pop:contact_high`) %>% psych::lowerCor()
library(bayesplot)
post %>% select(-lp__) %>% rename(b_interaction = `b_log_pop:contact_high`) %>%
  mcmc_intervals(prob = .5, prob_outer = .95) +
  theme(axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0))

# How plausible is it a high-contact island will have more tools than a low-contact island?
post <- post %>%
  mutate(lambda_high = exp(b_Intercept + b_contact_high + (b_log_pop + `b_log_pop:contact_high`)*8), # Backtransform
         lambda_low  = exp(b_Intercept + b_log_pop*8)) %>% 
  mutate(diff        = lambda_high - lambda_low) 

post %>%  summarise(sum = sum(diff > 0)/length(diff)) # 95.6 % of all counts
post %>%
  ggplot(aes(x = diff)) +
  geom_density(fill="red",alpha =.6) +
  geom_vline(xintercept = 0, linetype = 2) +
    labs(x = "lambda_high - lambda_low")

# ---- #

# no interaction
b10.11 <- 
  update(b10.10, formula = total_tools ~ 1 + log_pop + contact_high)

# no contact rate
b10.12 <-
  update(b10.10, formula = total_tools ~ 1 + log_pop)

# no log-population
b10.13 <-
  update(b10.10, formula = total_tools ~ 1 + contact_high)

# intercept only
b10.14 <-
  update(b10.10, formula = total_tools ~ 1)

w_b10.10 <- waic(b10.10)
w_b10.11 <- waic(b10.11)
w_b10.12 <- waic(b10.12)
w_b10.13 <- waic(b10.13)
w_b10.14 <- waic(b10.14)

compare_ic(w_b10.10, w_b10.11, w_b10.12, w_b10.13, w_b10.14)

# Do an ensemble posterior prediction
nd <-
  tibble(log_pop      = seq(from = 6.5, to = 13, length.out = 50) %>% 
           rep(., times = 2),
         contact_high = rep(0:1, each = 50))

ppa_10.9 <- 
  pp_average(b10.10, b10.11, b10.12, # The 3 best models
             weights = "loo", # Using loo
             method  = "fitted",
             newdata = nd) %>%
  as_tibble() %>%
  bind_cols(nd)

# Plot
ppa_10.9 %>%
  ggplot(aes(x     = log_pop,
             group = contact_high)) +
  geom_ribbon(aes(ymin = Q2.5,
                  ymax = Q97.5,
                  fill = contact_high),
              alpha = 1/4) +
  geom_line(aes(y = Estimate, color = contact_high)) +
  geom_text(data = d, 
             aes(y     = total_tools,
                 label = total_tools,
                 color = contact_high),
             size = 3.5) +
  coord_cartesian(xlim = c(7.1, 12.4),
                  ylim = c(12, 70)) +
  labs(x = "log population",
       y = "total tools",
       subtitle = "Blue is the high contact rate; black is the low.") +
  theme(legend.position = "none",
        panel.border    = element_blank())

# LOO weights
model_weights(b10.10, b10.11, b10.12, 
              weights = "loo")

# ----- #
# Lastly for exposure inclusion
set.seed(3838)

num_days  <- 30
y         <- rpois(num_days, 1.5)
num_weeks <- 4
y_new     <- rpois(num_weeks, 0.5*7)
d <- 
tibble(y         = c(y, y_new), 
       days      = c(rep(1, num_days), rep(7, num_weeks)),
       monastery = c(rep(0, num_days), rep(1, num_weeks))) %>%
mutate(log_days  = log(days))

b10.15 <-
  brm(data = d, family = poisson,
      y ~ 1 + offset(log_days) + monastery, # Specify offset with log days
      prior = c(prior(normal(0, 100), class = Intercept),
                prior(normal(0, 1), class = b)),
      iter = 2500, warmup = 500, cores = 2, chains = 2)

library(tidybayes)

posterior_samples(b10.15) %>%
  transmute(lambda_old = exp(b_Intercept),
            lambda_new = exp(b_Intercept + b_monastery)) %>%
  gather() %>%
  mutate(key = factor(key, levels = c("lambda_old", "lambda_new"))) %>%
  group_by(key) %>%
  mean_hdi(value, .width = .89) %>% 
  mutate_if(is.double, round, digits = 2)

# Leave it there ...


```

<br>

# Monsters and mixture (models) with brms # - 

```{r}
library(rethinking)
data(Trolley)
d <- Trolley

rm(Trolley)
detach(package:rethinking, unload = T)
library(brms)
library(tidyverse)
library(ggthemes)

# Here are our starting values, which we specify with the `inits` argument in brm()
inits <- list(`Intercept[1]` = -2,
              `Intercept[2]` = -1,
              `Intercept[3]` = 0,
              `Intercept[4]` = 1,
              `Intercept[5]` = 2,
              `Intercept[6]` = 2.5)

inits_list <- list(inits, inits)

b11.1 <- 
  brm(data = d, family = cumulative,
      response ~ 1,
      prior(normal(0, 10), class = Intercept),
      iter = 2000, warmup = 1000, cores = 2, chains = 2,
      inits = inits_list)  # Here we add our start values
print(b11.1)

# Get probability metrics
posterior_samples(b11.1) %>% 
  select(starts_with("b_")) %>% # those with an intercept
  mutate_all(inv_logit_scaled) %>%  # inv_log trasnform
  gather() %>% 
  group_by(key) %>% 
  summarise(mean = mean(value),
            sd   = sd(value),
            ll   = quantile(value, probs = .025), # lower limit
            ul   = quantile(value, probs = .975)) # upper limit


# Ordered logistic
# First, we needed to specify the `logistic()` function, which is apart of the `dordlogit()` function
logistic <- function(x) {
    p <- 1 / (1 + exp(-x))
    p <- ifelse(x == Inf, 1, p)
    p
    }

# Function from McElreath book
dordlogit <- 
  function(x, phi, a, log = FALSE) {
    a  <- c(as.numeric(a), Inf)
    p  <- logistic(a[x] - phi)
    na <- c(-Inf, a)
    np <- logistic(na[x] - phi)
    p  <- p - np
    if (log == TRUE) p <- log(p)
    p
    }

# --- #
# Lets fit the model
# Start values for b11.2
inits <- list(`Intercept[1]` = -1.9,
              `Intercept[2]` = -1.2,
              `Intercept[3]` = -0.7,
              `Intercept[4]` =  0.2,
              `Intercept[5]` =  0.9,
              `Intercept[6]` =  1.8,
              action         =  0,
              intention      =  0,
              contact        =  0)

b11.2 <- 
  brm(data = d, family = cumulative,
      response ~ 1 + action + intention + contact,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b)),
      iter = 2000, warmup = 1000, cores = 2, chains = 2,
      inits = list(inits, inits))

# Now with interaction
# Start values for b11.3
inits <- list(`Intercept[1]`      = -1.9,
              `Intercept[2]`      = -1.2,
              `Intercept[3]`      = -0.7,
              `Intercept[4]`      =  0.2,
              `Intercept[5]`      =  0.9,
              `Intercept[6]`      =  1.8,
              action              =  0,
              intention           =  0,
              contact             =  0,
              `action:intention`  =  0,
              `contact:intention` =  0)

b11.3 <- 
  update(b11.2,
         formula = response ~ 1 + action + intention + contact + action:intention + contact:intention,
         inits = list(inits, inits))

library(broom)
tidy(b11.1) %>% mutate(model = "b11.1") %>% 
  bind_rows(tidy(b11.2) %>% mutate(model = "b11.2")) %>% 
  bind_rows(tidy(b11.3) %>% mutate(model = "b11.3")) %>% 
  select(model, term, estimate) %>% 
  filter(term != "lp__") %>% 
  complete(term = distinct(., term), model) %>% 
  mutate(estimate = round(estimate, digits = 2)) %>%
  spread(key = model, value = estimate) %>% 
  # this last step isn't necessary, but it orders the rows to match the text
  slice(c(6:11, 1, 4, 3, 2, 5))

# WAIC comparison
waic(b11.1, b11.2, b11.3) 


```


# The zero inflated things

```{r}
library(tidyverse)
# define parameters
prob_drink <- 0.2  # 20% of days
rate_work  <- 1    # average 1 manuscript per day

# sample one year of production
N <- 365

# simulate days monks drink
set.seed(0.2)
drink <- rbinom(N, 1, prob_drink)

# simulate manuscripts completed
y <- (1 - drink) * rpois(N, rate_work)

d <-
  tibble(Y = y) %>%
  arrange(Y) %>% 
  mutate(zeros = c(rep("zeros_drink", times = sum(drink)),
                   rep("zeros_work",  times = sum(y == 0 & drink == 0)),
                   rep("none",        times = N - sum(y == 0))
                   )) 
# Fit
library(brms)
b11.4 <- 
  brm(data = d, family = zero_inflated_poisson,
      Y ~ 1,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(beta(2, 2), class = zi)),  # the brms default is beta(1, 1)
      cores = 4)

print(b11.4)

```

