---
title: "INLA tutorials"
output: html_notebook
---

Working through the online [INLA book](https://becarioprecario.bitbucket.io/inla-gitbook) and examples.

# Load necessary packages

```{r, echo=FALSE,eval=FALSE}
library(INLA)
#inla.pardiso() # PARADISO solver https://pardiso-project.org
library(tidyverse)
library(bayesplot)
library(ggplot2)
library("MASS")
library(broom)
```

# Integrated Nested Laplace Approximation (INLA)
'Havard Rue, Martino, and Chopin (2009) propose a novel approach that makes Bayesian inference faster. First of all, rather than aiming at estimating the joint posterior distribution of the model parameters, they suggest focusing on individual posterior marginals of the model parameters. In many cases, marginal inference is enough to make inference of the model parameters and latent effects, and there is no need to deal with multivariate posterior distributions that are difficult to obtain.'

# Multiple linear regression with INLA


```{r}

m1 <- inla(y ~ x1 + x2 + x3 + x4, data = cement)
plot(m1)
summary(m1)

# Other likelihoods available
names(inla.models()$likelihood)

# Poisson regression
library("spdep")
data(nc.sids)
    
# Overall rate
r <- sum(nc.sids$SID74) / sum(nc.sids$BIR74)

# Expected SIDS per county
nc.sids$EXP74 <- r * nc.sids$BIR74

# Proportion of non-white births
nc.sids$NWPROP74 <- nc.sids$NWBIR74 / nc.sids$BIR74

# Model
m.pois <- inla(SID74 ~ NWPROP74, data = nc.sids, family = "poisson",
  E = EXP74)

summary(m.pois)

# Add a gaussian distributed random effects to the model
m.poisover <- inla(SID74 ~ NWPROP74 + f(CNTY.ID, model = "iid"),
  data = nc.sids, family = "poisson", E = EXP74)

summary(m.poisover)

# Add index for latent effect
nc.sids$idx <- 1:nrow(nc.sids)
# Model fitting
m.poisover <- inla(SID74 ~ NWPROP74 + f(idx, model = "iid"),    
  data = nc.sids, family = "poisson", E = EXP74)
summary(m.poisover)

# CPO: For each observation CPO is the posterior probability of observing that observation when the model is fit using all data but y_i.

# PIT:  predictive integral transform (PIT) which measures, for each observation, the probability of a new value to be lower than the actual observed value:

# DIC & WAIC: Take into account goodness-of-fit and a penalty term that is based on the complexity of the model via the estimated effective number of parameters.

# Now calculate with model selection
# Poisson model
m.pois <- inla(SID74 ~ NWPROP74, data = nc.sids, family = "poisson",
  E = EXP74, control.compute = list(cpo = TRUE, dic = TRUE, waic = TRUE))

# Poisson model with iid random effects
m.poisover <- inla(SID74 ~ NWPROP74 + f(CNTY.ID, model = "iid"),
  data = nc.sids, family = "poisson", E = EXP74,
  control.compute = list(cpo = TRUE, dic = TRUE, waic = TRUE))

```


Other Control options

```{r}
?control.compute

library("ggplot2")
library("gridExtra")

# Posterior of coefficient of x1
plot1 <- ggplot(as.data.frame(m1$marginals.fixed$x1)) + 
  geom_line(aes(x = x, y = y)) +
  ylab (expression(paste(pi, "(", "x", " | ", bold(y), ")")))

# Posterior of precision
plot2 <- ggplot(as.data.frame(m1$marginals.hyperpar[[1]])) + 
  geom_line(aes(x = x, y = y)) +
  ylab (expression(paste(pi, "(", tau, " | ", bold(y), ")")))

grid.arrange(plot1, plot2, nrow = 2)

#  the probability of its coefficient being higher than one can be computed:
1 - inla.pmarginal(0, m1$marginals.fixed$x1)

# 95% HPD interval
inla.hpdmarginal(0.95, m1$marginals.hyperpar[[1]])

# Posterior marginal
marg.stdev <- inla.tmarginal(function(tau) tau^(-1/2), m1$marginals.hyperpar[[1]])
inla.zmarginal(marg.stdev)
# Posterior mean can also be computed like this
inla.emarginal(function(sigma) sigma, marg.stdev)
# Posterior mode of SD
inla.mmarginal(marg.stdev)

```

## Sampling from the posterior

```{r}

# Fit model with config = TRUE
m1 <- inla(y ~ x1 + x2 + x3 + x4, data = cement,
  control.compute = list(config = TRUE)) # Option for posterior samling

# Sample 100 times for variable x1 and x2
m1.samp <- inla.posterior.sample(100, m1, selection = list(x1 = 1, x2 = 1))
names(m1.samp[[1]])

m1.samp[[1]]

# Product of the two coefficients
x1x2.samp <- inla.posterior.sample.eval(function(...) {x1 * x2},
   m1.samp)

summary(as.vector(x1x2.samp))

# --- #
# Or sample the hyper parameter
# Sample hyperpars from joint posterior
set.seed(123)
  prec.samp <- inla.hyperpar.sample(1000, m1)


```


# Mixed effects models

linear as simple linear fixed effect. clinear as constrained linear fixed effect, constrained as ranges of possible values can be fixed.

```{r}
library(INLA)
library("spdep")
data(nc.sids)

# Overall rate
r <- sum(nc.sids$SID74) / sum(nc.sids$BIR74)
nc.sids$EXP74 <- r * nc.sids$BIR74

# Proportion of non-white births
nc.sids$NWPROP74 <- nc.sids$NWBIR74 / nc.sids$BIR74

# With linear effect
m.pois.lin1 <- inla(SID74 ~ f(NWPROP74, model = "linear"),
  data = nc.sids, family = "poisson", E = EXP74)

# Constrained range
m.pois.clin1 <- inla(SID74 ~ f(NWPROP74, model = "clinear",
  range = c(0, Inf)), data = nc.sids, family = "poisson",
  E = EXP74)

summary(m.pois.clin1)
```

Now for different types of random effects

```{r}

# iid 
# Often used for overdispersion
nc.sids$ID <- 1:100

m.pois.iid <- inla(SID74 ~ f(ID, model = "iid"),
  data = nc.sids, family = "poisson",
  E = EXP74)

summary(m.pois.iid)

m.pois.iid2 <- inla(SID74 ~ NWPROP74 + f(ID, model = "iid"),
  data = nc.sids, family = "poisson",
  E = EXP74)

summary(m.pois.iid2)

# ---- #
# Z latent model where z is is a defined matrix
m.pois.z <- inla(SID74 ~ f(ID, model = "z", Z = Diagonal(nrow(nc.sids), 1)),
  data = nc.sids, family = "poisson", E = EXP74)

summary(m.pois.z)

# Generic 0 random intercept
# fixed matrix C that is completely known and does not depend on any other hyperparameter
m.pois.g0 <- inla(SID74 ~ f(ID, model = "generic0", 
  Cmatrix = Diagonal(nrow(nc.sids), 1)),
  data = nc.sids, family = "poisson", E = EXP74)

summary(m.pois.g0)

# Generic 1 - matrix with separate entries for precision, known values and eigenvalues
# Generic 2 ?
# Generic 3

K1 <- Diagonal(nrow(nc.sids), 1)

m.pois.g2 <- inla(SID74 ~ f(ID, model = "generic3", Cmatrix = list(K1)),data = nc.sids, family = "poisson", E = EXP74)

summary(m.pois.g2)

# ------ #
# Correlated random effects
# Named after number of dimensions of correlated random effects
inla.doc("iid2d")

#Overall rate
r79 <- sum(nc.sids$SID79) / sum(nc.sids$BIR79)
nc.sids$EXP79 <- r79 * nc.sids$BIR79

#New data.frame
nc.new <- data.frame(SID = c(nc.sids$SID74, nc.sids$SID79),
  EXP = c(nc.sids$EXP74, nc.sids$EXP79),
  PERIOD = as.factor(c(rep("74", 100), rep("79", 100))),
  ID = 1:200)

m.pois.iid2d <- inla(SID ~ 0 + PERIOD + f(ID, model = "iid2d", n = 2 * 100),
  data = nc.new, family = "poisson", E = EXP)

summary(m.pois.iid2d)

# Random walks
# Although this is a discrete latent effect, it can be used to model continuous variables by using the values argument. In particular, the values of the covariate can be binned so that they are associated with a particular value of the vector of random effects. This is particularly interesting to model non-linear dependence on covariates in the linear predictor.

data(AirPassengers)

airp.data <- data.frame(airp = as.vector(AirPassengers),
  month = as.factor(rep(1:12, 12)), 
  year = as.factor(rep(1949:1960, each = 12)),
  ID = 1:length(AirPassengers))

# RW1
airp.rw1 <- inla(log(AirPassengers) ~ 0 + year + f(ID, model = "rw1"),
  control.family = list(hyper = list(prec = list(param = c(1, 0.2)))),
  data = airp.data, control.predictor = list(compute = TRUE))
summary(airp.rw1)

#RW2 (second order)
airp.rw2 <- inla(log(AirPassengers) ~ 0 + year + f(ID, model = "rw2"),
  control.family = list(hyper = list(prec = list(param = c(1, 0.2)))),
  data = airp.data, control.predictor = list(compute = TRUE))
summary(airp.rw2)

# Seasonal random effects
airp.seasonal <- inla(log(AirPassengers) ~ 0 + year +
    f(ID, model = "seasonal", season.length = 12),
  control.family = list(hyper = list(prec = list(param = c(1, 0.2)))),
  data = airp.data)
summary(airp.seasonal)

# AR models
# AR1
airp.ar1 <- inla(log(AirPassengers) ~ 0 + year + f(ID, model = "ar1"),
  control.family = list(hyper = list(prec = list(param = c(1, 0.2)))),
  data = airp.data, control.predictor = list(compute = TRUE))
summary(airp.ar1)

# Third order AR
airp.ar3 <- inla(log(AirPassengers) ~ 0 + year + f(ID, model = "ar",
    order = 3), 
  control.family = list(hyper = list(prec = list(param = c(1, 0.2)))),
  data = airp.data, control.predictor = list(compute = TRUE))
summary(airp.ar3)

# ar1c for covariate lag effects!
# in previous models covariate year has been included as part of the linear predictor. In the next model this covariate is included as part of an AR(1) model with covariates (i.e., a ar1c model):

Z <- model.matrix (~ 0 + year, data = airp.data)
Q.beta <- Diagonal(12, 0.001)

airp.ar1c <- inla(log(AirPassengers) ~ 1 + f(ID, model = "ar1c",
  args.ar1c = list(Z = Z, Q.beta = Q.beta)),
  control.family = list(hyper = list(prec = list(param = c(1, 0.2)))),
  data = airp.data, control.predictor = list(compute = TRUE))
summary(airp.ar1c)


```

Additional hyper parameters that can be defined in f()
<
  hyper 	Default priors 	Definition of priors for hyperparameters.
  constr 	FALSE 	Sum-to-zero constraint on the random effects.
  extraconstr 	FALSE 	Additional constraint on the random effects.
  scale.model 	FALSE 	Scale variance matrix of random effects.
  group 	— 	Variable to define the groups of random effect.
  control.group 	— 	Control options for group parameter.
>

```{r}
# Different prior for one model, gaussian mean 0 and sigma 1/1000
# More in priors later

m.pois.iid.gp <- inla(SID74 ~ f(ID, model = "iid",
    hyper = list(theta = list(prior = "gaussian", param = c(0, 0.001)))),
  data = nc.sids, family = "poisson",
  E = EXP74)

# Sum to zero constrain on random effect
m.pois.iid.gp0 <- inla(SID74 ~ f(ID, model = "iid", constr = TRUE),
  data = nc.sids, family = "poisson", E = EXP74)

summary(m.pois.iid.gp0)

# With extra constrains
n <- nrow(nc.sids)
A <- matrix(1, ncol = n, nrow = 1)
e <- rep(0, 1)
m.pois.iid.extrac <- inla(SID74 ~ 
    f(ID, model = "iid", extraconstr = list(A = A, e = e)),
  data = nc.sids, family = "poisson", E = EXP74)

# Grouped random effects
airp.data$month.num <- as.numeric(airp.data$month)
airp.data$year.num <- as.numeric(airp.data$year)
airp.iid.ar1 <- inla(log(airp) ~ 0 +  f(year.num, model = "iid",
    group = month.num, control.group = list(model = "ar1", 
    scale.model = TRUE)),
  data = airp.data)
summary(airp.iid.ar1)


# Other random effects
inla.doc()
```

